library(dplyr)
data(markers)
input <- markers$input %>% .[. != ""]
scone <- markers$scone %>% .[. != ""]
# Selection of the k. Default is number of cells / 100.
k <- nrow(com) %/% 100
# The above example is stored in the package as "markers," loaded here
library(Sconify)
data(markers)
input <- markers$input %>% .[. != ""]
scone <- markers$scone %>% .[. != ""]
# Selection of the k. Default is number of cells / 100.
k <- nrow(com) %/% 100
library(Sconify)
knitr::opts_chunk$set(echo = TRUE)
combined
combined
# The above example is stored in the package as "markers," loaded here
library(Sconify)
data(markers)
input <- markers$input %>% .[. != ""]
scone <- markers$scone %>% .[. != ""]
# Selection of the k. Default is number of cells / 100.
k <- nrow(com) %/% 100
# The above example is stored in the package as "markers," loaded here
library(Sconify)
data(markers)
input <- markers$input %>% .[. != ""]
scone <- markers$scone %>% .[. != ""]
# Selection of the k. Default is number of cells / 100.
k <- nrow(combined) %/% 100
# The built-in scone functions
nn <- fnn(cell.df = combined, input.markers = input, k = k)
%>%
1 + 1 %>%  mean
fnn(cell.df = combined, input.markers = input, k = k)
combined
fnn
input
markers
# The above example is stored in the package as "markers," loaded here
library(Sconify)
data(markers)
input <- markers$surface %>% .[. != ""]
scone <- markers$functional %>% .[. != ""]
# Selection of the k. Default is number of cells / 100.
k <- nrow(combined) %/% 100
# The built-in scone functions
nn <- fnn(cell.df = combined, input.markers = input, k = k)
# Cell identity is in rows, k-nearest neighbors are columns
# List of 2 includes the cell identity of each nn, and the euclidean distance between
#   itself and the cell of interest
str(nn)
nn
head(nn)
nn[1:100, 1:10]
# The above example is stored in the package as "markers," loaded here
library(Sconify)
data(markers)
input <- markers$surface %>% .[. != ""]
scone <- markers$functional %>% .[. != ""]
# Selection of the k. Default is number of cells / 100.
k <- nrow(combined) %/% 100
# The built-in scone functions
nn <- fnn(cell.df = combined, input.markers = input, k = k)
# Cell identity is in rows, k-nearest neighbors are columns
# List of 2 includes the cell identity of each nn, and the euclidean distance between
#   itself and the cell of interest
str(nn)
nn[1:100, 1:10]
# The above example is stored in the package as "markers," loaded here
library(Sconify)
data(markers)
input <- markers$surface %>% .[. != ""]
scone <- markers$functional %>% .[. != ""]
# Selection of the k. Default is number of cells / 100.
k <- nrow(combined) %/% 100
# The built-in scone functions
nn <- fnn(cell.df = combined, input.markers = input, k = k)
# Cell identity is in rows, k-nearest neighbors are columns
# List of 2 includes the cell identity of each nn, and the euclidean distance between
#   itself and the cell of interest
str(nn)
nn[1:20, 1:10]
nn
?save
?use_data
library(devtools)
document()
?use_data
use_data(nn)
input
use_data(input.markers)
# The above example is stored in the package as "markers," loaded here
library(Sconify)
# How to convert your excel sheet into vector of static and functional markers
data(markers)
# addition in the end gets rid of empty strings
input.markers <- markers$surface %>% .[. != ""]
funct.markers <- markers$functional %>% .[. != ""]
# Selection of the k. Default is number of cells / 100.
k <- nrow(combined) %/% 100
# The built-in scone functions
nn <- fnn(cell.df = combined, input.markers = input.markers, k = k)
# Cell identity is in rows, k-nearest neighbors are columns
# List of 2 includes the cell identity of each nn, and the euclidean distance between
#   itself and the cell of interest
str(nn)
nn[1:20, 1:10]
input.markers
use_data(input.markers)
use_data(funct.markers)
final <- scone.values(nn.matrix = nn,
cell.data = combined,
scone.markers = funct.markers,
unstim = "basal")
final
library(Sconify)
knitr::opts_chunk$set(echo = TRUE)
# The above example is stored in the package as "markers," loaded here
library(Sconify)
# How to convert your excel sheet into vector of static and functional markers
data(markers)
# addition in the end gets rid of empty strings
input.markers <- markers$surface %>% .[. != ""]
funct.markers <- markers$functional %>% .[. != ""]
# Selection of the k. Default is number of cells / 100.
k <- nrow(combined) %/% 100
# The built-in scone functions
nn <- fnn(cell.df = combined, input.markers = input.markers, k = k)
# Cell identity is in rows, k-nearest neighbors are columns
# List of 2 includes the cell identity of each nn, and the euclidean distance between
#   itself and the cell of interest
str(nn)
nn[1:20, 1:10]
library(Sconify)
knitr::opts_chunk$set(echo = TRUE)
# The above example is stored in the package as "markers," loaded here
library(Sconify)
# How to convert your excel sheet into vector of static and functional markers
data(markers)
# addition in the end gets rid of empty strings
input.markers <- markers$surface %>% .[. != ""]
funct.markers <- markers$functional %>% .[. != ""]
# Selection of the k. Default is number of cells / 100.
k <- nrow(combined) %/% 100
# The built-in scone functions
nn <- fnn(cell.df = combined, input.markers = input.markers, k = k)
# Cell identity is in rows, k-nearest neighbors are columns
# List of 2 includes the cell identity of each nn, and the euclidean distance between
#   itself and the cell of interest
str(nn)
nn[1:20, 1:10]
document()
library(Sconify)
document()
document()
document()
library(Sconify)
use_vignette("MultipleDonorScone")
source('~/Documents/endeavors/grad.school/garry.nolan.lab/dry.lab/scone/scripts/scone.scripts/general.scone.7.R')
# Converts multiple files into a concatenated data frame
# Args:
#   files: a vector of file names (name = "anything_condition.fcs")
#   numcells: desiered number of cells in the matrix
#   norm: boolean that quantile normalizes the data if true
#   scale: boolean that converts all values to z scores if true
#   name.multiple.donors: boolean indicating whether multiple donors will be distinguished (as a separate "patient" column)
# Returns:
#   result: a combined file set
# Notes:
#   This is tailored to a very specific file format for unstim/stim
#   Files need the following name convention: "xxxx_stim.fcs"
#   Files where you want to name the patients need the following convention: "xxxx__patientID_stim.fcs"
process.multiple.files.2 <- function(files, numcells, norm, scale, input, name.multiple.donors) {
n <- numcells %/% length(files) # integer division
# Turn input into a list
dat <- lapply(files, function(i){
curr <- fcs.to.data.frame(i) %>% .[,na.omit(colnames(.))] %>% as.tibble() # in case columns are named "NA"
# Subsample if the number of cells is greater than specified n
if(nrow(curr) > n) {
curr <- curr[sample(nrow(curr), n),]
}
# Break curr into the values you're going to normalize for knn generation and those you're not
curr.input <- curr[,input]
curr.rest <- curr[,(!(colnames(curr) %in% input))]
if(norm == TRUE) {
curr.input <- quantile_normalisation(curr.input) %>% as.tibble()
}
if(scale == TRUE) {
curr.input <- apply(curr.input, 2, scale) %>% as.tibble()
curr.input <- replace(curr.input, is.na(curr.input), 1) # takes care of scaling where all values are same
}
# Overwrite curr, bringing the (potentially normalized/scaled) curr.input and curr.rest together
curr <- bind_cols(curr.input, curr.rest)
# File standard: "anything_condition.fcs"
curr$condition <- sub(".*_", "", i) %>% sub("\\..*", "", .)
if(name.multiple.donors == TRUE) {
curr$donor <- sub(".*__", "", i) %>% sub("\\_.*", "", .)
}
return(curr)
})
# Bind the list of tibbles by the row
if(length(dat) > 1) {
result <- bind_rows(dat)
} else {
result <- dat[[1]]
}
return(result)
}
# Performs a series of statistical tests on the batch of cells of interest
# Args:
#   basal: tibble of cells corresponding to the unstimulated condition
#   stim: a tibble of cells corresponding to the stimulated condition
#   tests: a vector of strings that the user would like to output (min = statistical test + fold)
#   fold: a string that specifies the use of "median" or "mean" when calculating fold change
#   stat.test: a string that specifies Mann-Whitney U test (mwu) or T test (t) for q value calculation
#   stim.name: a string corresponding to the name of the stim being tested compared to basal
# Returns:
#   result: a named vector corresponding to the results of the "fold change" and mann-whitney u test
run.statistics <- function(basal, stim, fold, stat.test, stim.name) {
# Edge case of a knn consisting of only one of the two conditions
# More common in messier datasets
if(nrow(basal) == 0 | nrow(stim) == 0) {
return(rep(NA, times = 2*ncol(basal) + 1))
}
# Fold change between unstim and stim (output is named vector)
if(fold == "median") {
fold <- apply(stim, 2, median) - apply(basal, 2, median)
} else if (fold == "mean") {
fold <- apply(stim, 2, mean) - apply(basal, 2, mean)
} else {
stop("please select median or mean to be used as input for raw change calculation")
}
# Mann-Whitney U test or T test
if(stat.test == "mwu") {
qvalue <- sapply(1:ncol(basal), function(j) {
p <- wilcox.test(basal[[j]], stim[[j]])$p.value
return(p)
})
} else if (stat.test == 't') {
qvalue <- sapply(1:ncol(basal), function(j) {
p <- t.test(basal[[j]], stim[[j]])$p.value
return(p)
})
} else {
stop("please select either Mann-Whitney U test (mwu) or T test (t) for input")
return()
}
# Naming the vectors
names(qvalue) <- names(fold) # qvalue is not yet a named vector, so its named here
names(qvalue) <- paste(names(qvalue), stim.name, "qvalue", sep = ".") # specifying
names(fold) <- paste(names(fold), stim.name, "change", sep = ".") # specifying
# Get the unstim and stim thresholds done
fraction.cond2 <- nrow(stim)/sum(nrow(basal), nrow(stim))
names(fraction.cond2) <- paste(stim.name, "fraction.cond.2", sep = ".")
result <- c(qvalue, fold, fraction.cond2)
return(result)
}
# Runs a t test on the medians or means of multiple donors for the same condition
# Args:
#   basal: tibble that contains unstim for a knn including donor identity
#   stim: tibble that contains stim for a knn including donor identity
#   stim.name: string of the name of the current stim being tested
#   donors: vector of strings corresponding to the designated names of the donors
# Returns:
#   result: a named vector of p values (soon to be q values) from the t test done on each marker
multiple.donor.statistics <- function(basal, stim, stim.name, donors) {
# get the means of all the donors
basal.stats <- tibble()
stim.stats <- tibble()
for(i in donors) {
basal.curr <- basal[basal$donor == i,] %>% .[!(colnames(.) %in% "donor")]
stim.curr <- stim[stim$donor == i,] %>% .[!(colnames(.) %in% "donor")]
basal.mean <- apply(basal.curr, 2, mean)
stim.mean <- apply(stim.curr, 2, mean)
basal.stats <- rbind(basal.stats, basal.mean)
stim.stats <- rbind(stim.stats, stim.mean)
}
colnames(basal.stats) <- colnames(basal)[-ncol(basal)] # assumes "donor" always placed at end!
colnames(stim.stats) <- colnames(stim)[-ncol(basal)]
# T testing (only if there's no NA in the dataset)
if(nrow(na.omit(basal.stats)) == length(donors) & nrow(na.omit(stim.stats)) == length(donors)) {
result <- sapply(1:ncol(basal.stats), function(i) {
t.test(basal.stats[[i]], stim.stats[[i]])$p.value
})
} else {
result <- rep(NA, times = ncol(basal.stats))
}
names(result) <- paste(colnames(basal.stats), stim.name, "replicate.qvalue", sep = ".")
return(result)
}
# Makes list of all cells within knn, for each knn
# Args:
#   nn.matrix: a matrix of cell index by nearest neighbor index, with values being cell index of the nth nearest neighbor
#   cell.data: tibble of cells by features
#   scone.markers: vector of all markers to be interrogated via statistical testing
#   unstim: an object (used so far: string, number) specifying the "basal" condition
#   threshold: a number indicating the p value the raw change should be thresholded by.
#   fold: a string that specifies the use of "median" or "mean" when calculating fold change
#   stat.test: string denoting Mann Whitney U test ("mwu") or T test ("t)
#   multiple.donor.compare: a boolean that indicates whether t test across multiple donors should be done
# Returns:
#   result: tibble of raw changes and p values for each feature of interest, and fraction of cells with condition 2
scone.values.2 <- function(nn.matrix, cell.data, scone.markers, unstim, threshold, fold, stat.test, multiple.donor.compare) {
# Get the donor names if you need it
if(multiple.donor.compare == TRUE) {
donors <- unique(cell.data$donor)
}
# Get all stim.names
conditions <- unique(cell.data$condition)
stims <- conditions[!(conditions %in% unstim)]
# Variables to be used for progress tracker within the loop
percent <- nrow(cell.data) %/% 10
final <- lapply(stims, function(s) {
# Process each column in the nn matrix
# This makes a list of vecors corresponding qvalue and fold change
count <- 0
result <- lapply(1:nrow(nn.matrix), function(i) {
# A tracker
if(i %% percent == 0) {
count <<- count + 10
print(paste(count, "percent complete", sep = " "))
}
# Index the nn matrix
curr <- cell.data[nn.matrix[i,],]
basal <- curr[curr$condition == unstim,] %>% .[,scone.markers]
stim <- curr[curr$condition == s,] %>% .[,scone.markers] # Change this to specify stim name
# Fold change cmoparison and Mann-Whitney U test, along with "fraction condition 2"
output <- run.statistics(basal, stim, fold, stat.test, s)
# Note that this will overwrite the initial output (for now)
if(multiple.donor.compare == TRUE) {
nn.donors <- unique(curr$donor)
# We want multiple donor testing only if all donors are in each knn
if(length(unique(nn.donors)) < length(donors)) {
donor.output <- rep(NA, times = length(scone)) # Check length
} else {
basal.d <- curr[curr$condition == unstim,] %>% .[,c(scone.markers, "donor")]
stim.d <- curr[curr$condition == s,] %>% .[,c(scone.markers, "donor")]
donor.output <- multiple.donor.statistics(basal.d, stim.d, s, donors)
}
#names(donor.output) <- paste(scone, s, "donor.t.test.qvalue", sep = ".") # Name the donor t test vector
output <- c(output, donor.output)
}
return(output)
})
# Melt the list together into a tibble and return it
result <- do.call(rbind, result) %>%
as.tibble()
})
final <- do.call(cbind, final) %>%
as.tibble()
# Do the p value correction, followed by thresholding if you're going to
frac <- final[, grep("fraction", colnames(final))]
final <- q.correction.thresholding(final, threshold)
final <- bind_cols(final, frac)
# Change the only "character" column to a numeric column
return(final)
}
set.seed(1048305)
cells <- process.multiple.files.2(files = c(unstim, stims), numcells = 20000, norm = TRUE, scale = TRUE, input = input, name.multiple.donors = TRUE)
setwd("~/Documents/endeavors/grad.school/garry.nolan.lab/dry.lab/scone/gabi.surgery.stims/fcs")
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/scone/gabi.surgery.stims/fcs")
files <- list.files() %>% .[grep("fcs", .)]
markers <- read.csv("organized.markers.csv")
input <- markers$input %>% .[. != ""]
scone <- markers$scone %>% .[. != ""]
unstim <- files[grep("BL", files)]
stims <- files[!(files %in% unstim)]
set.seed(1048305)
cells <- process.multiple.files.2(files = c(unstim, stims), numcells = 20000, norm = TRUE, scale = TRUE, input = input, name.multiple.donors = TRUE)
unstim
stims
markers
input
scone
options(stringsAsFactors = FALSE)
files <- list.files() %>% .[grep("fcs", .)]
markers <- read.csv("organized.markers.csv")
input <- markers$input %>% .[. != ""]
scone <- markers$scone %>% .[. != ""]
unstim <- files[grep("BL", files)]
stims <- files[!(files %in% unstim)]
unstim
stims
files
dir()
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/scone/gabi.surgery.stims/fcs")
dir()
dir()
setwd("~/Library/Mobile Documents/com~apple~CloudDocs/scone/gabi.surgery.stims/fcs")
dir(
)
scone.values
final
knitr::opts_chunk$set(echo = TRUE, results = "markup", message = FALSE, warning = FALSE)
final <- scone.values(nn.matrix = nn,
cell.data = combined,
scone.markers = funct.markers,
unstim = "basal")
final
final
use_data(final)
dir()
setwd("~/Documents/local.R.projects/Sconify")
scone.output <- final
use_data(scone.output)
input.markers
document()
library(Sconify)
library(Sconify)
document()
document()
final <- post.processing(scone.output = scone.output,
cell.data = combined,
input = input.markers)
final
use_vignette("PostProcessing")
knitr::opts_chunk$set(echo = TRUE, results = "markup", message = FALSE, warning = FALSE)
final <- post.processing(scone.output = scone.output,
cell.data = combined,
input = input.markers)
combined # input data
scone.output # scone-generated data
final # the data after post-processing
final
qplot(final$bh-`bh-SNE1`, final$`bh-SNE2`)
qplot(final$bh-`bh-SNE1`, final$`bh-SNE2`)
qplot(final$`bh-SNE1`, final$`bh-SNE2`)
library(ggplot2)
qplot(final$`bh-SNE1`, final$`bh-SNE2`)
qplot(final$`bh-SNE1`, final$`bh-SNE2`, color = 'pSTAT5')
qplot(final$`bh-SNE1`, final$`bh-SNE2`, color = final$`pSTAT5(Nd150)Di.IL7.change`)
document()
library(Sconify)
final
ggplot(final, aes(x = final$`bh-SNE1`, y = final$`bh-SNE2`) + geom_point()
)
ggplot(final) + geom_point(aes(x = final$`bh-SNE1`, y = final$`bh-SNE2`))
ggplot(final) + geom_point(aes(x = final$`bh-SNE1`, y = final$`bh-SNE2`, color = final$`pSTAT5(Nd150)Di.IL7.change`))
document()
library(Sconify)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
test <- cbind(rnorm(100), rnorm(100))
ggplot(test) + geom_point(aes(x = test[,1], y = test[,2]))
library(ggplot2)
test <- data.frame(rnorm(100), rnorm(100))
ggplot(test) + geom_point(aes(x = test[,1], y = test[,2]))
library(ggplot2)
test <- data.frame(rnorm(100), rnorm(100))
ggplot(test) + geom_point(aes(x = test[,1], y = test[,2]), color = test[,1])
library(ggplot2)
test <- data.frame(rnorm(100), rnorm(100))
ggplot(test) + geom_point(aes(x = test[,1], y = test[,2]), color = 1)
library(ggplot2)
knitr::include_graphics()
qplot(final$`bh-SNE1`,
final$`bh-SNE2`,
color = final$`pSTAT5(Nd150)Di.IL7.change`,
xlab = "bh-SNE1",
ylab = "bh-SNE2")
qplot(final$`bh-SNE1`,
final$`bh-SNE2`,
color = final$`pSTAT5(Nd150)Di.IL7.change`,
xlab = "bh-SNE1",
ylab = "bh-SNE2") + scale_fill_discrete(name = "test")
qplot(final$`bh-SNE1`,
final$`bh-SNE2`,
color = final$`pSTAT5(Nd150)Di.IL7.change`,
xlab = "bh-SNE1",
ylab = "bh-SNE2") + guides(fill=guide_legend(title="New Legend Title"))
qplot(final$`bh-SNE1`,
final$`bh-SNE2`,
color = final$`pSTAT5(Nd150)Di.IL7.change`,
xlab = "bh-SNE1",
ylab = "bh-SNE2")
qplot(final$`bh-SNE1`,
final$`bh-SNE2`,
color = final$`pSTAT5(Nd150)Di.IL7.change`,
xlab = "bh-SNE1",
ylab = "bh-SNE2") + labs(color = "test")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.width=6, fig.height=4)
library(ggplot2)
test <- data.frame(rnorm(100), rnorm(100))
ggplot(test) + geom_point(aes(x = test[,1], y = test[,2]), color = 1) + scale_color_gradientn(colors = c("black", "yellow"))
range(final$`pSTAT5(Nd150)Di.IL7.change`)
hist(final$`pSTAT5(Nd150)Di.IL7.change`)
hist(final$`pSTAT5(Nd150)Di.IL7.change`, breaks = 100)
summary(final$`pSTAT5(Nd150)Di.IL7.change`)
document()
library(Sconify)
install.packages("devtools")
install.packages("devtools")
document()
library(Sconify)
document()
library(Sconify)
knitr::opts_chunk$set(echo = TRUE, results = "markup", message = FALSE, warning = FALSE)
library(Sconify)
# FCS file provided in the package
basal <- system.file('extdata',
'Bendall et al Cell Sample C_basal.fcs',
package = "Sconify")
# Example of data with no transformation
basal.raw <- fcs.to.tibble(basal, transform = "none")
basal.raw
# Asinh transformation with a scale argument of 5
basal.asinh <- fcs.to.tibble(basal, transform = "asinh")
basal.asinh
document()
