'markers.csv',
package = "Sconify")
str(markers)
markers.file
testthat("Markers csv file is successfully imported" {
markers <- parse.markers(markers.file)
expect_equal(length(markers), 2)
})
testthat("Markers csv file is successfully imported", {
markers <- parse.markers(markers.file)
expect_equal(length(markers), 2)
})
library(testthat)
testthat("Markers csv file is successfully imported", {
markers <- parse.markers(markers.file)
expect_equal(length(markers), 2)
})
test_that("Markers csv file is successfully imported", {
markers <- parse.markers(markers.file)
expect_equal(length(markers), 2)
})
devtools::test()
devtools::test
devtools::test()
devtools::test()
devtools::test()
test_check("Sconify")
devtools::test()
traceback()
devtools::test
devtools::test()
devtools::test()
test <- parse_markers("markers.csv")
test <- parse_markers(markers.file)
test <- parse.markers(markers.file)
test
length(test)
length(test[[1]])
length(test[[2]])
devtools::test
devtools::test()
devtools::test()
str(test[[1]])
names(markers)
devtools::test()
fcs.to.tibble(basal.file)
str(fcs.to.tibble(basal.file))
test_that("Markers csv file is successfully imported", {
markers <- parse.markers(markers.file)
expect_equal(length(markers), 2)
expect_equal(length(markers[[1]]), 27)
expect_equal(length(markers[[2]]), 16)
expect_equal(names(markers), c("input", "functional"))
expect_true(is.list(markers))
})
test_that("Fcs file gets converted into a tibble data structure", {
dat <- fcs.to.tibble(file = basal.file)
expect_true(is.tibble(dat))
expect_false(is.data.frame(dat))
})
test
test <- fcs.to.tibble(basal.file)
test
is.data.frame()
is.data.frame(test)
test_that("Fcs file gets converted into a tibble data structure", {
dat <- fcs.to.tibble(file = basal.file)
expect_true(is.tibble(dat))
expect_true(is.data.frame(dat))
expect_false(is.matrix(dat))
})
test_that("Fcs file gets converted into a tibble data structure", {
dat <- fcs.to.tibble(file = basal.file)
expect_true(is.tibble(dat))
expect_true(is.data.frame(dat))
expect_false(is.matrix(dat))
expect_true(is.vector(dat[[1]]))
})
test[[1]]
test
test[[3]]
str(test[[3]])
is.atomic(test[[3]])
test_that("Fcs file gets converted into a tibble data structure", {
dat <- fcs.to.tibble(file = basal.file)
expect_true(is.tibble(dat))
expect_true(is.data.frame(dat))
expect_false(is.matrix(dat))
expect_true(is.atomic(dat[[1]]))
})
fcs.to.tibble(file = "bullshit.fcs")
colnames(test)
test_that("The asinh transform command works", {
not.tr <- fcs.to.tibble(file = basal.file, transform = "none")
tr <- fcs.to.tibble(file = basal.file)
expect_equal(tr[[3]], asinh(not.tr[[3]]/5))
})
test_that("The asinh transform command works", {
not.tr <- fcs.to.tibble(file = basal.file, transform = "none")
tr <- fcs.to.tibble(file = basal.file)
tr2 <- fcs.to.tibble(file = basal.file, transform = "asinh")
expect_equal(tr[[3]], asinh(not.tr[[3]]/5))
expect_equal(tr[[3]], tr2[[3]])
})
devtools::test()
stim.file <- system.file('extdata',
'Bendall_et_al_Cell_Sample_C_IL7.fcs',
package = "Sconify")
stim.file
test_that("Processing multiple files works on a single file", {
dat1 <- fcs.to.tibble(file = basal.file)
dat2 <- process.multiple.files(files = basal.file, input = input)
expect_equal(dat1[,input], dat2[,input])
})
input <- parse.markers(markers.file)[[1]]
test_that("Processing multiple files works on a single file", {
dat1 <- fcs.to.tibble(file = basal.file)
dat2 <- process.multiple.files(files = basal.file, input = input)
expect_equal(dat1[,input], dat2[,input])
})
test_that("Processing multiple files works on a single file", {
dat1 <- fcs.to.tibble(file = basal.file)
dat2 <- process.multiple.files(files = basal.file, input = input)
expect_equal(dat1[,input], dat2[,input])
expect_false(all.equal(dat1, dat2))
})
all.equal(dat1, dart2)
all.equal(dat1, dat2)
dat1 <- fcs.to.tibble(file = basal.file)
dat2 <- process.multiple.files(files = basal.file, input = input)
all.equal(dat1, dat2)
all(dat1 == dat2)
dat1 = dat2
dat1 == dat2
all(dat1 == dat2)
length(dat1)
length(dat2)
dat1 <- fcs.to.tibble(file = basal.file)
dat2 <- process.multiple.files(files = basal.file, input = input)
length(dat1)
length(dat2)
test_that("Processing multiple files works on a single file", {
dat1 <- fcs.to.tibble(file = basal.file)
dat2 <- process.multiple.files(files = basal.file, input = input)
expect_equal(dat1[,input], dat2[,input])
expect_false(all.equal(dat1, dat2))
expect_equal(length(dat1) + 1, length(dat2))
})
test_that("Processing multiple files works on a single file", {
dat1 <- fcs.to.tibble(file = basal.file)
dat2 <- process.multiple.files(files = basal.file, input = input)
expect_equal(dat1[,input], dat2[,input])
expect_equal(length(dat1) + 1, length(dat2))
})
test_that("Processing multiple files works on a single file", {
dat1 <- fcs.to.tibble(file = basal.file)
dat2 <- process.multiple.files(files = basal.file, input = input)
expect_equal(dat1[,input], dat2[,input])
expect_equal(length(dat1) + 1, length(dat2))
expect_equal(length(unique(dat1[["condition"]])), 1)
})
test_that("Processing multiple files works on a single file", {
dat1 <- fcs.to.tibble(file = basal.file)
dat2 <- process.multiple.files(files = basal.file, input = input)
expect_equal(dat1[,input], dat2[,input])
expect_equal(length(dat1) + 1, length(dat2))
expect_equal(length(unique(dat2[["condition"]])), 1)
})
devtools::test()
test <- fcs.to.tibble(basal.file)
test
process.multiple.files(basal.file, numcells = 1, input = input)
process.multiple.files(basal.file, numcells = 0, input = input)
test_that("Process multiple files effectively sub-samples", {
cell.number <- nrow(fcs.to.tibble(basal.file))
testing <- c(cell.number,
cell.number %/% 2,
cell.number %/% 4,
cell.number %/% 8)
lapply(testing, function(i) {
curr <- process.multiple.files(files = basal.file, numcells = i,
input = input)
expect_equal(nrow(curr), i)
})
})
test_that("Process multiple files effectively sub-samples", {
cell.number <- nrow(fcs.to.tibble(basal.file))
testing <- c(cell.number,
cell.number %/% 2,
cell.number %/% 4,
cell.number %/% 8)
lapply(testing, function(i) {
curr <- process.multiple.files(files = basal.file, numcells = i,
input = input)
expect_equal(nrow(curr), i)
})
expect_error(process.multiple.files(files = basal.file, numcells = 0,
input = input))
expect_error(process.multiple.files(files = basal.file, numcells = -3,
input = input))
})
process.multiple.files(files = basal.file, input = input, numcells = 1.4)
is.integer(4)
is.integer(-4)
is.integer(4.5)
is.atomic(4.3)
is.double(5)
is.double(5.4)
is.whole
process.multiple.files(files = basal.file, input = input, numcells = 1.4)
process.multiple.files <- function(files,
transform = "asinh",
numcells = 10000,
norm = FALSE,
scale = FALSE,
input,
name.multiple.donors = FALSE) {
# Edge case
if(numcells < length(files) {
stop("Please select a subsampling number greater than the number
of files being used as input")
})
if(numcells %% 1 != 0) {
stop("Please select a subsampling number that is whole")
}
n <- numcells %/% length(files) # integer division
# Turn input into a list
dat <- lapply(files, function(i){
curr <- fcs.to.tibble(i, transform = transform) %>%
.[,na.omit(colnames(.))] %>%
as.tibble() # in case columns are named "NA"
# Subsample if the number of cells is greater than specified n
if(nrow(curr) > n) {
curr <- curr[sample(nrow(curr), n),]
}
# Break curr into the values you're going to normalize for
# knn generation and those you're not
curr.input <- curr[,input]
curr.rest <- curr[,(!(colnames(curr) %in% input))]
if(scale == TRUE) {
curr.input <- apply(curr.input, 2, scale) %>% as.tibble()
# takes care of scaling where all values are same
curr.input <- replace(curr.input, is.na(curr.input), 1)
}
# Overwrite curr, bringing the (potentially normalized/scaled)
# curr.input and curr.rest together
curr <- bind_cols(curr.input, curr.rest)
# File standard: "anything_condition.fcs"
curr$condition <- sub(".*_", "", i) %>% sub("\\..*", "", .)
if(name.multiple.donors == TRUE) {
curr$donor <- sub(".*__", "", i) %>% sub("\\_.*", "", .)
}
return(curr)
})
if(norm == TRUE) {
if(length(files) < 2) {
stop("Quantile normalization can only happen with 2 or more files")
}
# The list with only the input markers,
# and perform quantile normalization
dat.input <- lapply(dat, function(i) {
i[,input]
}) %>% quant.normalize.elements(.)
# The list with only the non-input markers
dat.rest <- lapply(dat, function(i) {
i[,(!(colnames(i) %in% input))]
})
# Merge the two lists together again
dat <- lapply(1:length(dat), function(i) {
bind_cols(dat.input[[i]], dat.rest[[i]])
})
}
# Bind the list of tibbles by the row
if(length(dat) > 1) {
result <- bind_rows(dat)
} else {
result <- dat[[1]]
}
return(result)
}
process.multiple.files <- function(files,
transform = "asinh",
numcells = 10000,
norm = FALSE,
scale = FALSE,
input,
name.multiple.donors = FALSE) {
# Edge case
if(numcells < length(files) {
stop("Please select a subsampling number greater than the number
of files being used as input")
})
if(numcells %% 1 != 0) {
stop("Please select a subsampling number that is whole")
}
n <- numcells %/% length(files) # integer division
# Turn input into a list
dat <- lapply(files, function(i){
curr <- fcs.to.tibble(i, transform = transform) %>%
.[,na.omit(colnames(.))] %>%
as.tibble() # in case columns are named "NA"
# Subsample if the number of cells is greater than specified n
if(nrow(curr) > n) {
curr <- curr[sample(nrow(curr), n),]
}
# Break curr into the values you're going to normalize for
# knn generation and those you're not
curr.input <- curr[,input]
curr.rest <- curr[,(!(colnames(curr) %in% input))]
if(scale == TRUE) {
curr.input <- apply(curr.input, 2, scale) %>% as.tibble()
# takes care of scaling where all values are same
curr.input <- replace(curr.input, is.na(curr.input), 1)
}
# Overwrite curr, bringing the (potentially normalized/scaled)
# curr.input and curr.rest together
curr <- bind_cols(curr.input, curr.rest)
# File standard: "anything_condition.fcs"
curr$condition <- sub(".*_", "", i) %>% sub("\\..*", "", .)
if(name.multiple.donors == TRUE) {
curr$donor <- sub(".*__", "", i) %>% sub("\\_.*", "", .)
}
return(curr)
})
if(norm == TRUE) {
if(length(files) < 2) {
stop("Quantile normalization can only happen with 2 or more files")
}
# The list with only the input markers,
# and perform quantile normalization
dat.input <- lapply(dat, function(i) {
i[,input]
}) %>% quant.normalize.elements(.)
# The list with only the non-input markers
dat.rest <- lapply(dat, function(i) {
i[,(!(colnames(i) %in% input))]
})
# Merge the two lists together again
dat <- lapply(1:length(dat), function(i) {
bind_cols(dat.input[[i]], dat.rest[[i]])
})
}
# Bind the list of tibbles by the row
if(length(dat) > 1) {
result <- bind_rows(dat)
} else {
result <- dat[[1]]
}
return(result)
}
process.multiple.files <- function(files,
transform = "asinh",
numcells = 10000,
norm = FALSE,
scale = FALSE,
input,
name.multiple.donors = FALSE) {
# Edge case
if(numcells < length(files)) {
stop("Please select a subsampling number greater than the number
of files being used as input")
}
if(numcells %% 1 != 0) {
stop("Please select a subsampling number that is whole")
}
n <- numcells %/% length(files) # integer division
# Turn input into a list
dat <- lapply(files, function(i){
curr <- fcs.to.tibble(i, transform = transform) %>%
.[,na.omit(colnames(.))] %>%
as.tibble() # in case columns are named "NA"
# Subsample if the number of cells is greater than specified n
if(nrow(curr) > n) {
curr <- curr[sample(nrow(curr), n),]
}
# Break curr into the values you're going to normalize for
# knn generation and those you're not
curr.input <- curr[,input]
curr.rest <- curr[,(!(colnames(curr) %in% input))]
if(scale == TRUE) {
curr.input <- apply(curr.input, 2, scale) %>% as.tibble()
# takes care of scaling where all values are same
curr.input <- replace(curr.input, is.na(curr.input), 1)
}
# Overwrite curr, bringing the (potentially normalized/scaled)
# curr.input and curr.rest together
curr <- bind_cols(curr.input, curr.rest)
# File standard: "anything_condition.fcs"
curr$condition <- sub(".*_", "", i) %>% sub("\\..*", "", .)
if(name.multiple.donors == TRUE) {
curr$donor <- sub(".*__", "", i) %>% sub("\\_.*", "", .)
}
return(curr)
})
if(norm == TRUE) {
if(length(files) < 2) {
stop("Quantile normalization can only happen with 2 or more files")
}
# The list with only the input markers,
# and perform quantile normalization
dat.input <- lapply(dat, function(i) {
i[,input]
}) %>% quant.normalize.elements(.)
# The list with only the non-input markers
dat.rest <- lapply(dat, function(i) {
i[,(!(colnames(i) %in% input))]
})
# Merge the two lists together again
dat <- lapply(1:length(dat), function(i) {
bind_cols(dat.input[[i]], dat.rest[[i]])
})
}
# Bind the list of tibbles by the row
if(length(dat) > 1) {
result <- bind_rows(dat)
} else {
result <- dat[[1]]
}
return(result)
}
process.multiple.files(files = basal.file, input = input, numcells = 1.4)
process.multiple.files(files = basal.file, input = input, numcells = 1)
process.multiple.files(files = basal.file, input = input, numcells = 0)
process.multiple.files(files = basal.file, input = input, numcells = -4)
test_that("Process multiple files effectively sub-samples", {
cell.number <- nrow(fcs.to.tibble(basal.file))
testing <- c(cell.number,
cell.number %/% 2,
cell.number %/% 4,
cell.number %/% 8)
lapply(testing, function(i) {
curr <- process.multiple.files(files = basal.file, numcells = i,
input = input)
expect_equal(nrow(curr), i)
})
expect_error(process.multiple.files(files = basal.file, numcells = 0,
input = input))
expect_error(process.multiple.files(files = basal.file, numcells = -3,
input = input))
expect_error(process.multiple.files(files = basal.file, numcells = 10.76,
input = input))
})
devtools::test()
test_that("Process multiple files divdes the contribution of each file equally", {
testing <- c(100, 99, 2)
lapply(testing, function(i) {
dat <- process.multiple.files(files = basal.file, numcells = 99,
input = input)
cond.dat <- dat[["condition"]]
conds <- unique(cond.dat)
cond1 <- cond.dat[cond.dat == conds[1]]
cond2 <- cond.dat[cond.dat == conds[2]]
expect_equal(length(cond1), length(cond2))
})
})
test_that("Process multiple files divdes the contribution of each file equally", {
testing <- c(100, 99, 2)
lapply(testing, function(i) {
dat <- process.multiple.files(files = basal.file, numcells = 99,
input = input)
cond.dat <- dat[["condition"]]
conds <- unique(cond.dat)
cond1 <- cond.dat[cond.dat == conds[1]]
cond2 <- cond.dat[cond.dat == conds[2]]
expect_equal(length(cond1), length(cond2) + 1)
})
})
test_that("Process multiple files effectively sub-samples", {
cell.number <- nrow(fcs.to.tibble(basal.file))
testing <- c(cell.number,
cell.number %/% 2,
cell.number %/% 4,
cell.number %/% 8)
lapply(testing, function(i) {
curr <- process.multiple.files(files = basal.file, numcells = i,
input = input)
expect_equal(nrow(curr), i)
})
expect_error(process.multiple.files(files = basal.file, numcells = 0,
input = input))
expect_error(process.multiple.files(files = basal.file, numcells = -3,
input = input))
expect_error(process.multiple.files(files = basal.file, numcells = 10.76,
input = input))
expect_error(process.multiple.files(files = c(basal.file, stim.file), numcells = 1,
input = input))
})
test_that("Process multiple files divdes the contribution of each file equally", {
testing <- c(100, 99, 2)
lapply(testing, function(i) {
dat <- process.multiple.files(files = basal.file, numcells = 99,
input = input)
cond.dat <- dat[["condition"]]
conds <- unique(cond.dat)
cond1 <- cond.dat[cond.dat == conds[1]]
cond2 <- cond.dat[cond.dat == conds[2]]
expect_equal(length(cond1), length(cond2))
})
})
devtools::test()
n1 <- rnorm(100, sd = 1)
n2 <- rnorm(100, sd = 10)
n1
n2
t.test(n1, n2)
wilcox.test(n1, n2)
var.test(n1, n2)
n1 <- rnorm(100, sd = 1)
n2 <- rnorm(100, sd = 1.3)
var.test(n1, n2)
n2 <- rnorm(100, sd = 2)
var.test(n1, n2)
