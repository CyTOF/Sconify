# File standard: "anything_condition.fcs"
curr$condition <- sub(".*_", "", i) %>% sub("\\..*", "", .)
if(name.multiple.donors == TRUE) {
curr$donor <- sub(".*__", "", i) %>% sub("\\_.*", "", .)
}
return(curr)
})
if(norm == TRUE) {
if(length(files) < 2) {
stop("Quantile normalization can only happen with 2 or more files")
}
# The list with only the input markers,
# and perform quantile normalization
dat.input <- lapply(dat, function(i) {
i[,input]
}) %>% quant.normalize.elements(.)
# The list with only the non-input markers
dat.rest <- lapply(dat, function(i) {
i[,(!(colnames(i) %in% input))]
})
# Merge the two lists together again
dat <- lapply(1:length(dat), function(i) {
bind_cols(dat.input[[i]], dat.rest[[i]])
})
}
# Bind the list of tibbles by the row
if(length(dat) > 1) {
result <- bind_rows(dat)
} else {
result <- dat[[1]]
}
return(result)
}
process.multiple.files <- function(files,
transform = "asinh",
numcells = 10000,
norm = FALSE,
scale = FALSE,
input,
name.multiple.donors = FALSE) {
# Edge case
if(numcells < length(files) {
stop("Please select a subsampling number greater than the number
of files being used as input")
})
if(numcells %% 1 != 0) {
stop("Please select a subsampling number that is whole")
}
n <- numcells %/% length(files) # integer division
# Turn input into a list
dat <- lapply(files, function(i){
curr <- fcs.to.tibble(i, transform = transform) %>%
.[,na.omit(colnames(.))] %>%
as.tibble() # in case columns are named "NA"
# Subsample if the number of cells is greater than specified n
if(nrow(curr) > n) {
curr <- curr[sample(nrow(curr), n),]
}
# Break curr into the values you're going to normalize for
# knn generation and those you're not
curr.input <- curr[,input]
curr.rest <- curr[,(!(colnames(curr) %in% input))]
if(scale == TRUE) {
curr.input <- apply(curr.input, 2, scale) %>% as.tibble()
# takes care of scaling where all values are same
curr.input <- replace(curr.input, is.na(curr.input), 1)
}
# Overwrite curr, bringing the (potentially normalized/scaled)
# curr.input and curr.rest together
curr <- bind_cols(curr.input, curr.rest)
# File standard: "anything_condition.fcs"
curr$condition <- sub(".*_", "", i) %>% sub("\\..*", "", .)
if(name.multiple.donors == TRUE) {
curr$donor <- sub(".*__", "", i) %>% sub("\\_.*", "", .)
}
return(curr)
})
if(norm == TRUE) {
if(length(files) < 2) {
stop("Quantile normalization can only happen with 2 or more files")
}
# The list with only the input markers,
# and perform quantile normalization
dat.input <- lapply(dat, function(i) {
i[,input]
}) %>% quant.normalize.elements(.)
# The list with only the non-input markers
dat.rest <- lapply(dat, function(i) {
i[,(!(colnames(i) %in% input))]
})
# Merge the two lists together again
dat <- lapply(1:length(dat), function(i) {
bind_cols(dat.input[[i]], dat.rest[[i]])
})
}
# Bind the list of tibbles by the row
if(length(dat) > 1) {
result <- bind_rows(dat)
} else {
result <- dat[[1]]
}
return(result)
}
process.multiple.files <- function(files,
transform = "asinh",
numcells = 10000,
norm = FALSE,
scale = FALSE,
input,
name.multiple.donors = FALSE) {
# Edge case
if(numcells < length(files)) {
stop("Please select a subsampling number greater than the number
of files being used as input")
}
if(numcells %% 1 != 0) {
stop("Please select a subsampling number that is whole")
}
n <- numcells %/% length(files) # integer division
# Turn input into a list
dat <- lapply(files, function(i){
curr <- fcs.to.tibble(i, transform = transform) %>%
.[,na.omit(colnames(.))] %>%
as.tibble() # in case columns are named "NA"
# Subsample if the number of cells is greater than specified n
if(nrow(curr) > n) {
curr <- curr[sample(nrow(curr), n),]
}
# Break curr into the values you're going to normalize for
# knn generation and those you're not
curr.input <- curr[,input]
curr.rest <- curr[,(!(colnames(curr) %in% input))]
if(scale == TRUE) {
curr.input <- apply(curr.input, 2, scale) %>% as.tibble()
# takes care of scaling where all values are same
curr.input <- replace(curr.input, is.na(curr.input), 1)
}
# Overwrite curr, bringing the (potentially normalized/scaled)
# curr.input and curr.rest together
curr <- bind_cols(curr.input, curr.rest)
# File standard: "anything_condition.fcs"
curr$condition <- sub(".*_", "", i) %>% sub("\\..*", "", .)
if(name.multiple.donors == TRUE) {
curr$donor <- sub(".*__", "", i) %>% sub("\\_.*", "", .)
}
return(curr)
})
if(norm == TRUE) {
if(length(files) < 2) {
stop("Quantile normalization can only happen with 2 or more files")
}
# The list with only the input markers,
# and perform quantile normalization
dat.input <- lapply(dat, function(i) {
i[,input]
}) %>% quant.normalize.elements(.)
# The list with only the non-input markers
dat.rest <- lapply(dat, function(i) {
i[,(!(colnames(i) %in% input))]
})
# Merge the two lists together again
dat <- lapply(1:length(dat), function(i) {
bind_cols(dat.input[[i]], dat.rest[[i]])
})
}
# Bind the list of tibbles by the row
if(length(dat) > 1) {
result <- bind_rows(dat)
} else {
result <- dat[[1]]
}
return(result)
}
process.multiple.files(files = basal.file, input = input, numcells = 1.4)
process.multiple.files(files = basal.file, input = input, numcells = 1)
process.multiple.files(files = basal.file, input = input, numcells = 0)
process.multiple.files(files = basal.file, input = input, numcells = -4)
test_that("Process multiple files effectively sub-samples", {
cell.number <- nrow(fcs.to.tibble(basal.file))
testing <- c(cell.number,
cell.number %/% 2,
cell.number %/% 4,
cell.number %/% 8)
lapply(testing, function(i) {
curr <- process.multiple.files(files = basal.file, numcells = i,
input = input)
expect_equal(nrow(curr), i)
})
expect_error(process.multiple.files(files = basal.file, numcells = 0,
input = input))
expect_error(process.multiple.files(files = basal.file, numcells = -3,
input = input))
expect_error(process.multiple.files(files = basal.file, numcells = 10.76,
input = input))
})
devtools::test()
test_that("Process multiple files divdes the contribution of each file equally", {
testing <- c(100, 99, 2)
lapply(testing, function(i) {
dat <- process.multiple.files(files = basal.file, numcells = 99,
input = input)
cond.dat <- dat[["condition"]]
conds <- unique(cond.dat)
cond1 <- cond.dat[cond.dat == conds[1]]
cond2 <- cond.dat[cond.dat == conds[2]]
expect_equal(length(cond1), length(cond2))
})
})
test_that("Process multiple files divdes the contribution of each file equally", {
testing <- c(100, 99, 2)
lapply(testing, function(i) {
dat <- process.multiple.files(files = basal.file, numcells = 99,
input = input)
cond.dat <- dat[["condition"]]
conds <- unique(cond.dat)
cond1 <- cond.dat[cond.dat == conds[1]]
cond2 <- cond.dat[cond.dat == conds[2]]
expect_equal(length(cond1), length(cond2) + 1)
})
})
test_that("Process multiple files effectively sub-samples", {
cell.number <- nrow(fcs.to.tibble(basal.file))
testing <- c(cell.number,
cell.number %/% 2,
cell.number %/% 4,
cell.number %/% 8)
lapply(testing, function(i) {
curr <- process.multiple.files(files = basal.file, numcells = i,
input = input)
expect_equal(nrow(curr), i)
})
expect_error(process.multiple.files(files = basal.file, numcells = 0,
input = input))
expect_error(process.multiple.files(files = basal.file, numcells = -3,
input = input))
expect_error(process.multiple.files(files = basal.file, numcells = 10.76,
input = input))
expect_error(process.multiple.files(files = c(basal.file, stim.file), numcells = 1,
input = input))
})
test_that("Process multiple files divdes the contribution of each file equally", {
testing <- c(100, 99, 2)
lapply(testing, function(i) {
dat <- process.multiple.files(files = basal.file, numcells = 99,
input = input)
cond.dat <- dat[["condition"]]
conds <- unique(cond.dat)
cond1 <- cond.dat[cond.dat == conds[1]]
cond2 <- cond.dat[cond.dat == conds[2]]
expect_equal(length(cond1), length(cond2))
})
})
devtools::test()
n1 <- rnorm(100, sd = 1)
n2 <- rnorm(100, sd = 10)
n1
n2
t.test(n1, n2)
wilcox.test(n1, n2)
var.test(n1, n2)
n1 <- rnorm(100, sd = 1)
n2 <- rnorm(100, sd = 1.3)
var.test(n1, n2)
n2 <- rnorm(100, sd = 2)
var.test(n1, n2)
df <- cbind(1:10, 11:20, 21:30)
df
test_that("Quantile normalization only happens with two or more files", {
expect_error(process.multiple.files(basal.file, input))
})
library(Sconify)
library(testthat)
context("Test the file processing arm of the Sconify package")
basal.file <- system.file('extdata',
'Bendall_et_al_Cell_Sample_C_basal.fcs',
package = "Sconify")
stim.file <- system.file('extdata',
'Bendall_et_al_Cell_Sample_C_IL7.fcs',
package = "Sconify")
markers.file <- system.file('extdata',
'markers.csv',
package = "Sconify")
test_that("Quantile normalization only happens with two or more files", {
expect_error(process.multiple.files(basal.file, input))
})
process.multiple.files(basal.file, input)
?as.tibble
df
as.tibble(df)
as_tibble(df)
library(tibble)
as.tibble(df)
library(Sconify)
library(testthat)
Sconify::process.multiple.files(basal.file, input)
basal.file <- system.file('extdata',
'Bendall_et_al_Cell_Sample_C_basal.fcs',
package = "Sconify")
basal.file <- system.file('extdata',
'Bendall_et_al_Cell_Sample_C_basal.fcs',
package = "Sconify")
stim.file <- system.file('extdata',
'Bendall_et_al_Cell_Sample_C_IL7.fcs',
package = "Sconify")
markers.file <- system.file('extdata',
'markers.csv',
package = "Sconify")
input <- parse.markers(markers.file)[[1]]
input <- parse.markers(markers.file)[[1]]
?parse.markers
?read.csv
?read_csv
library(Sconify)
basal.file <- system.file('extdata',
'Bendall_et_al_Cell_Sample_C_basal.fcs',
package = "Sconify")
stim.file <- system.file('extdata',
'Bendall_et_al_Cell_Sample_C_IL7.fcs',
package = "Sconify")
markers.file <- system.file('extdata',
'markers.csv',
package = "Sconify")
input <- parse.markers(markers.file)[[1]]
test_that("Quantile normalization only happens with two or more files", {
expect_error(process.multiple.files(basal.file, input))
})
process.multiple.files(basal.file, input)
input
expect_error(process.multiple.files(basal.file, input = input))
process.multiple.files(basal.file, input = input)
library(Sconify)
library(testthat)
context("Test the file processing arm of the Sconify package")
basal.file <- system.file('extdata',
'Bendall_et_al_Cell_Sample_C_basal.fcs',
package = "Sconify")
stim.file <- system.file('extdata',
'Bendall_et_al_Cell_Sample_C_IL7.fcs',
package = "Sconify")
markers.file <- system.file('extdata',
'markers.csv',
package = "Sconify")
input <- parse.markers(markers.file)[[1]]
test_that("Markers csv file is successfully imported", {
markers <- parse.markers(markers.file)
expect_equal(length(markers), 2)
expect_equal(length(markers[[1]]), 27)
expect_equal(length(markers[[2]]), 16)
expect_equal(names(markers), c("input", "functional"))
expect_true(is.list(markers))
})
test_that("Fcs file gets converted into a tibble data structure", {
dat <- fcs.to.tibble(file = basal.file)
expect_true(is.tibble(dat))
expect_true(is.data.frame(dat))
expect_false(is.matrix(dat))
expect_true(is.atomic(dat[[1]]))
})
test_that("The asinh transform command works", {
not.tr <- fcs.to.tibble(file = basal.file, transform = "none")
tr <- fcs.to.tibble(file = basal.file)
tr2 <- fcs.to.tibble(file = basal.file, transform = "asinh")
expect_equal(tr[[3]], asinh(not.tr[[3]]/5))
expect_equal(tr[[3]], tr2[[3]])
})
test_that("Processing multiple files works on a single file", {
dat1 <- fcs.to.tibble(file = basal.file)
dat2 <- process.multiple.files(files = basal.file, input = input)
expect_equal(dat1[,input], dat2[,input])
expect_equal(length(dat1) + 1, length(dat2))
expect_equal(length(unique(dat2[["condition"]])), 1)
})
test_that("Process multiple files effectively sub-samples", {
cell.number <- nrow(fcs.to.tibble(basal.file))
testing <- c(cell.number,
cell.number %/% 2,
cell.number %/% 4,
cell.number %/% 8)
lapply(testing, function(i) {
curr <- process.multiple.files(files = basal.file, numcells = i,
input = input)
expect_equal(nrow(curr), i)
})
expect_error(process.multiple.files(files = basal.file, numcells = 0,
input = input))
expect_error(process.multiple.files(files = basal.file, numcells = -3,
input = input))
expect_error(process.multiple.files(files = basal.file, numcells = 10.76,
input = input))
expect_error(process.multiple.files(files = c(basal.file, stim.file), numcells = 1,
input = input))
})
test_that("Process multiple files divdes the contribution of each file equally", {
testing <- c(100, 99, 2)
lapply(testing, function(i) {
dat <- process.multiple.files(files = basal.file, numcells = 99,
input = input)
cond.dat <- dat[["condition"]]
conds <- unique(cond.dat)
cond1 <- cond.dat[cond.dat == conds[1]]
cond2 <- cond.dat[cond.dat == conds[2]]
expect_equal(length(cond1), length(cond2))
})
})
test_that("Quantile normalization only happens with two or more files", {
expect_error(process.multiple.files(basal.file, input = input))
})
test_that("Quantile normalization only happens with two or more files", {
expect_error(process.multiple.files(basal.file, input = input, norm = TRUE))
})
library(Sconify)
dat <- list(tibble(1:10, 1:10), tibble(11:20, 11:20))
dat <- list(c1 = tibble(1:10, 1:10), c2 = tibble(11:20, 11:20))
dat <- list(cbind(1:10, 1:10) %>% as.tibble, cbind(11:20, 11:20) %>% as.tibble)
dat
library(magrittr)
library(Sconify)
Sconify::meaning.of.life()
Sconify::quant.normalize.elements
devtools::document()
library(Sconify)
quant.normalize.elements(dat)
dat <- list(cbind(1:10, 11:20) %>% as.tibble, cbind(21:30, 31:40) %>% as.tibble)
quant.normalize.elements(dat)
quant.normalize.elements(list(1:10, 11:20))
dat.list[[1]]
quant.normalize.elements(list(tibble(v1 = 1:10), tibble(v1 = 11:20))
)
test_that("Simple quantile normalization case", {
dat <- list(tibble(v1 = 1:10), tibble(v1 = 11:20))
q.dat <- quant.normalize.elements(dat)
expect_equal(dat[[1]], dat[[2]])
})
test_that("Simple quantile normalization case", {
dat <- list(tibble(v1 = 1:10), tibble(v1 = 11:20))
q.dat <- quant.normalize.elements(dat)
expect_equal(q.dat[[1]], q.dat[[2]])
})
dat
dat <- list(tibble(v1 = 1:10), tibble(v1 = 11:20))
dat
dat <- list(tibble(v1 = 1:10), tibble(v1 = 1:10))
quant.normalize.elements(dat)
dat <- list(tibble(v1 = 1:10), tibble(v1 = c(2, 4, 6, 8, 10, 12, 14, 16, 18, 20)))
dat
quant.normalize.elements(dat)
dat <- list(tibble(v1 = 1:5), tibble(v2 = 2, 4, 6, 8, 10))
quant.normalize.elements(dat)
test_that("Simple quantile normalization case", {
dat <- list(tibble(v1 = 1:10), tibble(v1 = 11:20))
q.dat <- quant.normalize.elements(dat)
expect_equal(q.dat[[1]], q.dat[[2]])
dat <- list(tibble(v1 = 1:5), tibble(v2 = 2, 4, 6, 8, 10))
q.dat <- quant.normalize.elements(dat)
expect_equal(q.dat[[1]], q.dat[[2]])
})
dat <- list(tibble(v1 = c(1, 3, 5, 7)), tibble(v2 = c(2, 4, 6, 8)))
dat
dat <- list(tibble(v1 = c(1, 3, 5, 7)), tibble(v2 = c(2, 4, 6, 8)))
quant.normalize.elements(dat)
test_that("Simple quantile normalization case", {
dat <- list(tibble(v1 = 1:10), tibble(v1 = 11:20))
q.dat <- quant.normalize.elements(dat)
expect_equal(q.dat[[1]], q.dat[[2]])
dat <- list(tibble(v1 = 1:5), tibble(v2 = 2, 4, 6, 8, 10))
q.dat <- quant.normalize.elements(dat)
expect_equal(q.dat[[1]], q.dat[[2]])
dat <- list(tibble(v1 = c(1, 3, 5, 7)), tibble(v2 = c(2, 4, 6, 8)))
q.dat <- quant.normalize.elements(dat)
expect_equal(q.dat[[1]], q.dat[[2]])
})
dat <- list(tibble(v1 = c(1, 2, 7, 9)), tibble(v2 = c(3, 4, 5, 6)))
dat
quant.normalize.elements(dat)
dat <- list(tibble(v1 = c(1, 2, 7, 9)), tibble(v2 = c(3, 4, 5, 3)))
dat
quant.normalize.elements(dat)
test_check("Sconify")
library(Sconify)
library(testthat)
library(Sconify)
test_check("Sconify")
test_check("Sconify")
library(Sconify)
library(testthat)
library(magrittr)
library(tibble)
context("Test the file processing arm of the Sconify package")
test_check("Sconify")
?test_check
devtools::test()
test_that("File is split down the middle", {
dat <- splitFile(basal.file, numcells = 10000, input.markers = input)
expect_equal(length(unique(dat$condition)), 2)
})
splitFile(c(basal.file, stim.file), numcells = 10000, input.markers = input))
splitFile(c(basal.file, stim.file), numcells = 10000, input.markers = input)
splitFile(c(basal.file, stim.file), numcells = 10000, input.markers = input)$condition
devtools::document()
library(Sconify)
test_that("Split file can only be run on a single file", {
expect_error(splitFile(c(basal.file, stim.file), numcells = 10000, input.markers = input))
})
splitFile(c(basal.file, stim.file), numcells = 10000, input.markers = input))
splitFile(c(basal.file, stim.file), numcells = 10000, input.markers = input)
test_that("Split file handles an odd number of cells", {
dat <- splitFile(basal.file, numcells = 99, input.markers = input)
expect_equal(nrow(dat), 98)
})
exist
devtools::test()
devtools::test()
