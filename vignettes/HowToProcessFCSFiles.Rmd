---
title: "How to process FCS files for downstream use in R"
author: "Tyler J Burns"
date: September 29, 2017
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{How to process FCS files for downstream use in R}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, results = "markup", message = FALSE, warning = FALSE)
```

TL:DR: 
You will use get.marker.names() to obtain properly named markers as a column in a csv saved to your computer. In this csv, you will make two columns, one for markers you want as input for knn, and one for markers you want to make your scone comparisons on. You will read this back into R to access these markers as vectors of strings. You'll then run process.multiple.files() to get your subsampled, concatenated matrix ready for KNN computation. 

Introduction: 
Fluorescence and mass cytometry data are routinely processed by an increasing array of software platforms. Many of these contain graphical user interfaces, and many of these are R packages. However, no two analyses are the same, and many cases may involve direct processing of files in R. The Sconify package provides a suite of functions to make this process simpler and more user-friendly, prior to the knn-centric analysis occurring downstream. In essence, these functions convert fcs files into data matrices, process these matrices, and can output said matrices into fcs files readable by additional software. Although the primary intent of these functions is to pre-process fcs files for use of k-nearest neighbor statistics and visualizations in the remainder of this package, they are intended also to be general use functions. 

Data: 
We will be using the Wanderlust dataset through this vignette and TheSconeWorkflow vignette. (https://www.ncbi.nlm.nih.gov/pubmed/24766814). We show a particular donor (labeled Sample C), with B cell precursors at the basal state, and stimulated with IL-7. In the paper, this reveals a small subset of precursors elevating its levels of pSTAT5 in relation to the rest of the cells.  

Getting the right markers out of your file:
Flow and mass cytometry experiments can have their parameters listed in different ways. If processing data directly within R, one needs to have vectors of strings containing these markers exactly as they are written in the fcs file. Thus, I provide a function to get these names in a spreadsheet and organize them accoringly.
Marker selection is performed using the get.marker.names() function. This function takes in an fcs file of interest and returns a list of markers, which is downloaded to your computer as markers.csv where the markers show up as a single column. If you want to filter out markers that will exist in the data matrix, you can modify the column in a program like excel. If you want to organize the markers into categories, with the primary example being static (eg. surface) and functional (eg. phospho), then you can create two columns with the respective markers of interest and label them "static" and "functional" accordingly. Save the spreadsheet as a csv file, and you're ready to use this downstream in the computational pipelines of interest. 

```
# Example fcs file
basal <- system.file('extdata',
    'Bendall et al Cell Sample C_basal.fcs',
     package = "Sconify")

# Run this, and check your directory for "markers.csv"
get.marker.names(basal)

# Turn this into two columns, one for surface markers, and one for phosphos
# Label the two columns accoridngly. Save to csv. You'll read this modified
# file in the process.multiple.files() function.

```

From fcs file to data matrix (a general function).

I provide here a general function that takes a single fcs file as input, performs an asinh transformation with a scale argument of 5 (for CyTOF) if instructed to, and converts the final output into a tibble. For SCONE, you'll use process.multiple.files(), which has this function embedded inside it. I provide it as well for any instance where you simply want to read a fcs file into R. 

```{r}

library(Sconify)

# FCS file provided in the package
basal <- system.file('extdata',
    'Bendall et al Cell Sample C_basal.fcs',
    package = "Sconify")

# Example of data with no transformation
basal.raw <- fcs.to.tibble(basal, transform = "none")
basal.raw

# Asinh transformation with a scale argument of 5
basal.asinh <- fcs.to.tibble(basal, transform = "asinh")
basal.asinh

```

This is the function that will be used for SCONE. 

There are other instances in data analysis where one will want to 1) subsample the data, and 2) process multiple files at the same time for downstream analysis, and 3) normalize the data in the files to each other. I therefore include a more robust function process.mulitiple.files() which does just this. One can include a vector of one or more markers as input, which is used for quantile normalization and downstream processing. If multiple files are used, the data will be conatenated into a single labeled tibble with an additional column containing "condition" information for each cell (which file it came from). If multiple donors as used, an additional column can be added with this information as well. Per marker, the files can be quantile normalized (across files), or z score transformed. If one only wants a subsample for downstream analysis (given space and time constrains), then random subsampling will occur per file, returning an even number of cells per file in the concatenated tibble.

```{r}
# The FCS files
basal <- system.file('extdata',
    'Bendall et al Cell Sample C_basal.fcs',
     package = "Sconify")
il7 <- system.file('extdata',
    'Bendall et al Cell Sample C_IL7.fcs',
    package = "Sconify")

# The markers (after they were modified by hand as instructed above)
markers <- system.file('extdata',
    'markers.csv',
    package = "Sconify")
markers <- read.csv(markers, stringsAsFactors = FALSE)
surface <- markers$surface

# Combining these. Note that default is sub-sampling to 10,000 cells, not normalizing, and not scaling
combined <- process.multiple.files(files = c(basal, il7), input = surface)
combined
unique(combined$condition)

# Limit your matrix to surface markers, if just using those downstream
combined.input <- combined[,surface]
combined.input

# We can do this on a single file as well. Notice I allow for scaling and I change the number of cells
basal.data <- process.multiple.files(files = basal, numcells = 6000, scale = TRUE, input = surface)
basal.data
unique(basal.data$condition)

```

For the type of condition versus basal analysis shown above, it may behoove the user to have a control containing two basal files being compared to each other (eg. with phospho-protein shifts across clusters). To this end, I developed a function called splitFile() that takes in a single file as input and splits it into two sub-matricies such that one group of cells can be the "treated" condition. 

```{r}
# The FCS files
basal <- system.file('extdata',
    'Bendall et al Cell Sample C_basal.fcs',
    package = "Sconify")
markers <- system.file('extdata',
    'markers.csv',
    package = "Sconify")

# The markers
markers <- read.csv(markers, stringsAsFactors = FALSE)
surface <- markers$surface

# The function
split <- splitFile(file = basal, input.markers = surface)
split
unique(split$condition)

```


From data matrix to fcs file:
After processing fcs files with the functions included here, and additional downstream analysis, one may want to convert the data back into fcs files to be read into fcs processing software, such as FlowJo or Cytobank. As such, I include a wrapper for FlowCore functionality, called data.to.fcs, that does just this. I also include the option to "un-transform" the data, if it has been asinh transformed with a co-factor of 5 initially. You specify the name of the output file, and it gets saved to your working directory accordingly.

```
basal <- system.file('extdata',
    'Bendall et al Cell Sample C_basal.fcs',
    package = "Sconify")
basal <- fcs.to.tibble(basal, transform = "asinh")
data.to.fcs(basal, "basal.output.FCS", untransform = TRUE)

```

Conclusions: 
The suite of functions I have provided here will allow for more complex fluorescence and mass cytometry analysis, with the particular focus on the downstream analyses in this package. Outside of knn statistics, this ranges from modifications of the data prior to reading it into a program like Cytobank, trying novel machine learning algorithms on the raw data, or developing entirely new algoirthms for this type of analysis. Subsequent versions of this package will have added functionality depending on the requests of the users. I hope these pre-processing functions will lower the barriers to entry for raw analysis of the data through R or other programming languages. It's not as hard as it looks. I promise. 

